# -*- coding: utf-8 -*-
"""Copy of Covid19_Twitter_SentimentAnalysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vubDMYSMNQ2N4WXYAW6ybyI3G615uWRK
"""

# Install Tweepy
!pip install tweepy

import time # To add delays
from datetime import datetime
import re
import tweepy
from tweepy import OAuthHandler
Time = []
consumer_api_key = 'HEywkAx6SCwKGeK9dO9njsl2w'
consumer_api_secret = 'ZX6bH3HVB4nr7bbhWm683Cw0PH8W1XpVDdgz5Wc2wcDoUhoDE3' 
access_token = '1315948924784517120-r3GyOgZYUJZO0bf2xkddFKR4ijVu0c'
access_token_secret ='DCHrI6EmxGUTN6vjrraH0sG9fxcSoSjENgmVSIxNXMlGq'

def hourSkip():
  time.sleep(3600)

def minuteSkip():
  time.sleep(60)

authorizer = OAuthHandler(consumer_api_key, consumer_api_secret)
authorizer.set_access_token(access_token, access_token_secret)

api = tweepy.API(authorizer ,timeout=15)
all_tweets = []
search_query = input("Search Term: ")
now = datetime.now()
Time.append(now.strftime("%H:%M"))

for tweet_object in tweepy.Cursor(api.search,q=search_query+" -filter:retweets",lang='en',result_type='recent').items(200):
    all_tweets.append(tweet_object.text)

print(all_tweets)

import numpy as np 
import pandas as pd 
import re  
import nltk # an amazing library to play with natural language
nltk.download('stopwords')  
from nltk.corpus import stopwords



tweets = pd.read_csv("https://raw.githubusercontent.com/kolaveridi/kaggle-Twitter-US-Airline-Sentiment-/master/Tweets.csv")
print(tweets)



X = tweets.iloc[:, 10].values  
y = tweets.iloc[:, 1].values

print(X)

processed_tweets = []
 
for tweet in range(0, len(X)):  
    # Remove all the special characters
    processed_tweet = re.sub(r'\W', ' ', str(X[tweet]))
 
    # remove all single characters
    processed_tweet = re.sub(r'\s+[a-zA-Z]\s+', ' ', processed_tweet)
 
    # Remove single characters from the start
    processed_tweet = re.sub(r'\^[a-zA-Z]\s+', ' ', processed_tweet) 
 
    # Substituting multiple spaces with single space
    processed_tweet= re.sub(r'\s+', ' ', processed_tweet, flags=re.I)
 
    # Removing prefixed 'b'
    processed_tweet = re.sub(r'^b\s+', '', processed_tweet)
 
    # Converting to Lowercase
    processed_tweet = processed_tweet.lower()
 
    processed_tweets.append(processed_tweet)

from sklearn.feature_extraction.text import TfidfVectorizer  
tfidfconverter = TfidfVectorizer(max_features=2000, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))  
X = tfidfconverter.fit_transform(processed_tweets).toarray()

from sklearn.ensemble import RandomForestClassifier
text_classifier = RandomForestClassifier(n_estimators=100, random_state=0)  
text_classifier.fit(X, y)

neutral = 0
positive = 0
negative = 0

for tweet in all_tweets:
    # Remove all the special characters
    processed_tweet = re.sub(r'\W', ' ', tweet)
 
    # remove all single characters
    processed_tweet = re.sub(r'\s+[a-zA-Z]\s+', ' ', processed_tweet)
 
    # Remove single characters from the start
    processed_tweet = re.sub(r'\^[a-zA-Z]\s+', ' ', processed_tweet) 
 
    # Substituting multiple spaces with single space
    processed_tweet= re.sub(r'\s+', ' ', processed_tweet, flags=re.I)
 
    # Removing prefixed 'b'
    processed_tweet = re.sub(r'^b\s+', '', processed_tweet)
 
    # Converting to Lowercase
    processed_tweet = processed_tweet.lower()
 
    sentiment = text_classifier.predict(tfidfconverter.transform([ processed_tweet]).toarray())
    print(processed_tweet ,":", sentiment)

    # For Each for loop run, increment the variables 
    if sentiment == "neutral" :
      neutral += 1
    elif sentiment == "positive":
      positive += 1
    elif sentiment == "negative":
      negative += 1


print("Neutral: " + str(neutral))
print("Positive: " + str(positive))
print("Negative: " + str(negative))

# average_sentiment variable aggregates the general positivity of people's views as a percentage of 100
average_sentiment = round(((neutral * 50 + positive * 100) / (neutral + positive + negative)), 2)
print(f'Average Sentiment on "{search_query}": {average_sentiment}%')



# With this code I open up a blank csv file with a dynamic name and overwrite 
# the contents with the Positive, Neutral, Negative values

# Note, need to work on appending (if file already exists) and date/timestamping
# the functionality is introduced.

import csv

with open(f'sentiment_of_{search_query}.csv', 'w', newline='') as file:
  writer = csv.writer(file)
  writer.writerow(["Sentiment", "Number"])
  writer.writerow(["Positive", positive])
  writer.writerow(["Neutral", neutral])
  writer.writerow(["Negative", negative])

file.close

import matplotlib.pyplot as plt

# Pie chart - slices get ordered and plotted counter-clockwise:
labels = 'Positive', 'Neutral', 'Negative'
sizes = [positive, neutral, negative] 

fig1, ax1 = plt.subplots()
ax1.pie(sizes, labels=labels, autopct='%1.1f%%',
        shadow=True, startangle=90)
ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle

plt.show()